{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EleonoraBaim/NPS_Dialogue_system/blob/main/NB_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPdtjWTV7wrD"
      },
      "source": [
        "# Installing and importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UtP7Y7i4tqTZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import pickle\n",
        "import time\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from catboost import Pool, CatBoostClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, hamming_loss, accuracy_score\n",
        "\n",
        "project_path = \"/content/drive/MyDrive/Colab_Notebooks/NPS_dialogue_system/\"\n",
        "#project_path = \"/NPS/\"\n",
        "\n",
        "min_df = 1/1000\n",
        "max_df = 1/20\n",
        "dataset_folder = \"ready_datasets/\"\n",
        "model_path = 'model_parts/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9Q2J4fNIDRg",
        "outputId": "b3c3759b-c9af-47b8-b397-edae02ef0ba8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.0.3-cp37-none-manylinux1_x86_64.whl (76.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.3 MB 72 kB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.6)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzIxog4Stg1h",
        "outputId": "38342a6e-4dc0-452e-8692-dc673e52c91c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amBKf6yubnLM"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BJ1B5wIobmVI"
      },
      "outputs": [],
      "source": [
        "def tf_idf_transform (data, tf_idf_model):\n",
        "  import tqdm\n",
        "\n",
        "  feature_names_text = tf_idf_model.get_feature_names()\n",
        "  data_text = pd.DataFrame(tf_idf_model.transform(data).toarray())\n",
        "  \n",
        "  data_text_names = pd.DataFrame()\n",
        "  for column in tqdm.tqdm(data_text.columns):\n",
        "    data_text_names[str('T ' + feature_names_text[column])] = data_text[column]\n",
        "    \n",
        "  data = data_text_names\n",
        "  data = data.fillna('NaN')\n",
        "  return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7IjxBAT7rfy"
      },
      "source": [
        "# 1.0 Data Importing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DPi_KjhtoFi",
        "outputId": "489dbcbf-0904-4251-a150-5d500965ea56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importing data... \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#IMPORTING DATA\n",
        "print('Importing data...', '\\n')\n",
        "\n",
        "train_df = pd.read_csv(str(project_path + dataset_folder + 'train_dataset.csv'))\n",
        "train_df.drop(labels = 'Unnamed: 0', axis = 1, inplace = True)\n",
        "\n",
        "test_df = pd.read_csv(str(project_path + dataset_folder + 'test_dataset.csv'))\n",
        "test_df.drop(labels = 'Unnamed: 0', axis = 1, inplace = True)\n",
        "\n",
        "val_df = pd.read_csv(str(project_path + dataset_folder + 'val_dataset.csv'))\n",
        "val_df.drop(labels = 'Unnamed: 0', axis = 1, inplace = True)\n",
        "\n",
        "text = 'CONTEXT'\n",
        "norm_text = 'normalized'\n",
        "target_list = train_df.columns[(train_df.columns!='CONTEXT')&(train_df.columns!='normalized')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI50bRJbb6e3"
      },
      "source": [
        "# 2.0 Data Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ve2HmAcu8DBs",
        "outputId": "1a00ce9f-8c84-4b05-c96f-fad5f3e55565"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Vectorization: \n",
            "Vocab size text: 2175\n",
            "Text vectoriztor saved to /content/drive/MyDrive/Colab_Notebooks/NPS_dialogue_system/model_parts//tfidf_vectorizer_text.pickle\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "100%|██████████| 2175/2175 [00:07<00:00, 310.32it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "100%|██████████| 2175/2175 [00:02<00:00, 907.54it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "100%|██████████| 2175/2175 [00:02<00:00, 753.54it/s]\n"
          ]
        }
      ],
      "source": [
        "print('Text Vectorization: ')\n",
        "\n",
        "# Создаем векторизатор\n",
        "tfidf_text = TfidfVectorizer(ngram_range=(1, 2), min_df=min_df, max_df=max_df)\n",
        "tfidf_text.fit(train_df[norm_text])\n",
        "\n",
        "print('Vocab size text: ' + str(len(tfidf_text.vocabulary_)))\n",
        "\n",
        "with open(str(project_path + model_path +  'tfidf_vectorizer_text.pickle'), 'wb') as handle:\n",
        "    pickle.dump(tfidf_text, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    print('Text vectoriztor saved to ' + str(project_path + model_path +'/'+'tfidf_vectorizer_text.pickle'))\n",
        "\n",
        "train_data = tf_idf_transform(train_df[norm_text], tfidf_text)\n",
        "test_data = tf_idf_transform(test_df[norm_text], tfidf_text)\n",
        "val_data = tf_idf_transform(val_df[norm_text], tfidf_text)\n",
        "\n",
        "tfdf_cols = train_data.columns\n",
        "\n",
        "train_data = train_data.join(train_df)\n",
        "val_data = val_data.join(val_df)\n",
        "test_data = test_data.join(test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlcQndr4CHXC"
      },
      "source": [
        "# 3.0 Model training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqs7k2GcCP8v"
      },
      "source": [
        "## 3.1 NB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ig2BaeoHFUZ",
        "outputId": "5966bb98-f1d7-4f3d-9574-16599806b85c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time of training:  --- 12.89266037940979 seconds ---\n",
            "Classification report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.33      0.43       146\n",
            "           1       0.83      0.39      0.53       284\n",
            "           2       0.70      0.33      0.45       482\n",
            "           3       0.64      0.05      0.10       133\n",
            "           4       0.77      0.20      0.32       458\n",
            "           5       0.93      0.29      0.45        95\n",
            "           6       0.80      0.56      0.66       321\n",
            "           7       0.74      0.47      0.58       525\n",
            "           8       0.88      0.30      0.45       184\n",
            "           9       0.81      0.27      0.40       160\n",
            "          10       0.96      0.27      0.42       250\n",
            "          11       0.88      0.24      0.38       123\n",
            "          12       0.90      0.13      0.22       218\n",
            "          13       0.86      0.23      0.36       502\n",
            "          14       0.75      0.55      0.63       498\n",
            "          15       0.86      0.17      0.29       181\n",
            "          16       0.00      0.00      0.00       196\n",
            "          17       0.00      0.00      0.00       127\n",
            "          18       0.88      0.05      0.10       137\n",
            "          19       0.33      0.00      0.01       207\n",
            "          20       0.85      0.71      0.77       408\n",
            "          21       1.00      0.03      0.06       165\n",
            "          22       0.83      0.24      0.37       186\n",
            "          23       0.98      0.18      0.30       234\n",
            "          24       0.80      0.02      0.04       197\n",
            "          25       1.00      0.07      0.12       169\n",
            "          26       0.94      0.45      0.61        64\n",
            "          27       0.70      0.45      0.55       432\n",
            "          28       1.00      0.50      0.66       141\n",
            "          29       0.80      0.72      0.75       905\n",
            "          30       0.98      0.30      0.46       395\n",
            "          31       1.00      0.14      0.24       111\n",
            "          32       0.80      0.59      0.68      1147\n",
            "          33       0.91      0.59      0.71       483\n",
            "          34       1.00      0.04      0.07        81\n",
            "          35       1.00      0.02      0.04       106\n",
            "          36       1.00      0.01      0.03       140\n",
            "          37       0.00      0.00      0.00        31\n",
            "          38       0.67      0.20      0.31      1946\n",
            "\n",
            "   micro avg       0.79      0.35      0.48     12568\n",
            "   macro avg       0.78      0.26      0.35     12568\n",
            "weighted avg       0.78      0.35      0.44     12568\n",
            " samples avg       0.42      0.38      0.38     12568\n",
            "\n",
            "Hamming Loss: \n",
            " 0.028941569859974103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "model_NB = MultiOutputRegressor(MultinomialNB())\n",
        "\n",
        "start_time = time.time()\n",
        "model_NB.fit(train_data[tfdf_cols], train_data[target_list])\n",
        "print('Time of training: ', \"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "preds_NB = model_NB.predict(test_data[tfdf_cols])\n",
        "\n",
        "print('Classification report: \\n', classification_report(test_data[target_list], preds_NB))\n",
        "print('Hamming Loss: \\n', hamming_loss(test_data[target_list], preds_NB))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2pEU282CMNP"
      },
      "source": [
        "## 3.2 Cat Boost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSbs01X9K-AI",
        "outputId": "1d7e3f95-7ed1-4621-c43e-1ca5f07a5d74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.0403743\ttest: 0.0390511\tbest: 0.0390511 (0)\ttotal: 4.09s\tremaining: 3h 24m 33s\n",
            "1000:\tlearn: 0.0283614\ttest: 0.0283666\tbest: 0.0283604 (998)\ttotal: 54m\tremaining: 1h 47m 50s\n",
            "2000:\tlearn: 0.0242994\ttest: 0.0256099\tbest: 0.0256099 (2000)\ttotal: 1h 46m 16s\tremaining: 53m 3s\n",
            "2999:\tlearn: 0.0217886\ttest: 0.0241444\tbest: 0.0241444 (2999)\ttotal: 2h 38m 32s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.02414444351\n",
            "bestIteration = 2999\n",
            "\n",
            "Time of training:  --- 9514.871947288513 seconds ---\n"
          ]
        }
      ],
      "source": [
        "task_type = 'CPU'\n",
        "\n",
        "model_CB = CatBoostClassifier(iterations=3000, random_state=1, learning_rate=0.05, verbose=1000,\n",
        "                           od_type=\"Iter\", od_wait=200, eval_metric='HammingLoss', use_best_model=True, depth=4, loss_function='MultiCrossEntropy',task_type=task_type)\n",
        "\n",
        "p_train = Pool(train_data[tfdf_cols], train_data[target_list])\n",
        "p_val = Pool(val_data[tfdf_cols], val_data[target_list])\n",
        "\n",
        "start_time = time.time()\n",
        "model_CB.fit(p_train, eval_set=p_val)\n",
        "print('Time of training: ', \"--- %s seconds ---\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "hRli7YVSHwNs"
      },
      "outputs": [],
      "source": [
        "model_CB.save_model(str(project_path+model_path+'cat_boost_v2.cbm'),\n",
        "           format=\"cbm\",\n",
        "           export_parameters=None,\n",
        "           pool=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "V2k92x35vFLq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be79c1fd-44df-4c27-fdf9-e789ec65e974"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report:                precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.53      0.63       146\n",
            "           1       0.81      0.85      0.83       284\n",
            "           2       0.78      0.37      0.50       482\n",
            "           3       0.76      0.20      0.31       133\n",
            "           4       0.83      0.32      0.46       458\n",
            "           5       0.87      0.42      0.57        95\n",
            "           6       0.85      0.58      0.69       321\n",
            "           7       0.79      0.50      0.61       525\n",
            "           8       0.85      0.86      0.86       184\n",
            "           9       0.78      0.61      0.69       160\n",
            "          10       0.82      0.77      0.79       250\n",
            "          11       0.83      0.57      0.68       123\n",
            "          12       0.74      0.44      0.55       218\n",
            "          13       0.80      0.34      0.47       502\n",
            "          14       0.81      0.54      0.65       498\n",
            "          15       0.82      0.88      0.85       181\n",
            "          16       0.56      0.07      0.13       196\n",
            "          17       0.62      0.06      0.11       127\n",
            "          18       0.68      0.20      0.31       137\n",
            "          19       0.65      0.05      0.10       207\n",
            "          20       0.91      0.83      0.87       408\n",
            "          21       0.63      0.12      0.19       165\n",
            "          22       0.80      0.33      0.47       186\n",
            "          23       0.95      0.52      0.67       234\n",
            "          24       0.83      0.22      0.35       197\n",
            "          25       0.90      0.33      0.48       169\n",
            "          26       0.86      0.88      0.87        64\n",
            "          27       0.91      0.47      0.62       432\n",
            "          28       0.99      0.96      0.97       141\n",
            "          29       0.86      0.68      0.76       905\n",
            "          30       0.95      0.46      0.62       395\n",
            "          31       0.82      0.30      0.44       111\n",
            "          32       0.87      0.67      0.76      1147\n",
            "          33       0.89      0.78      0.83       483\n",
            "          34       0.88      0.43      0.58        81\n",
            "          35       0.83      0.27      0.41       106\n",
            "          36       0.81      0.19      0.30       140\n",
            "          37       1.00      0.10      0.18        31\n",
            "          38       0.74      0.26      0.38      1946\n",
            "\n",
            "   micro avg       0.84      0.48      0.61     12568\n",
            "   macro avg       0.82      0.46      0.55     12568\n",
            "weighted avg       0.82      0.48      0.58     12568\n",
            " samples avg       0.57      0.51      0.52     12568\n",
            "\n",
            "Hamming Loss:  0.023823872082278735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "preds_CB = model_CB.predict(test_data[tfdf_cols])\n",
        "\n",
        "print('Classification report: ',classification_report(test_data[target_list], preds_CB))\n",
        "print(\"Hamming Loss: \", hamming_loss(test_data[target_list], preds_CB))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "NB_V2.ipynb",
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNDjK02+R4wRmzCj8DqUY/5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}